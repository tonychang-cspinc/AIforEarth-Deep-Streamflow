{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
      "local data directory. If you'd instead prefer to read directly from our public\n",
      "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
      "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04461c15acb44bdca39e0ef29d2e3301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >image</th>        <th class=\"col_heading level0 col1\" >label</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA40lEQVR4nGNgGJpg//8OdCEWKM2obvgv/++6/zcZnJQebPuNqkjvLxI4IIgiJ3/v79/3b//9/fvv7993f/9NQzE2TZ6hc8J3JwYGBgaGK7cYeJE12n79+1cCxlH9+/cVB5LOlxy/pryHSUYyMO78gSR5W/vzU7gxfAz/cfq36fvfDw445Fr+/P3bg12KMebb37+7WbDKKSz89/fvNRmscjpb//79u0YBq5z0yb9//2bhcEvXv78fs1ixyzX//PsuHYc+gbvwAMcEmX//3kFzJxOc9YCRoesJLp3sx9+p4JIjGQAAnrpmBs0pxioAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "                        <td id=\"T_c9894dd6_f2c7_11ea_bd13_0242ac110002row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0\n",
       "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "mnist = tfds.load('mnist', with_info=True)\n",
    "tfds.as_dataframe(mnist[0]['train'].take(4),mnist[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, Flatten, Conv2D,\\\n",
    "                        BatchNormalization, Concatenate, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from src.analysis_tools import plot_confusion_matrix, extract_data\n",
    "from src.cnn_models import basic_cnn, simple_cnn, dense_cnn, coeff_determination, rmse\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datadrive/stream_data/training/GrantPoole-training_metadata.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4a399c7a063a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfile_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/datadrive/stream_data/training/{datafile}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmetadata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/datadrive/stream_data/training/{station_name}-training_metadata.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'element_spec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datadrive/stream_data/training/GrantPoole-training_metadata.json'"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "import json\n",
    "stations = ['GrantPoole', 'BrownsBrook','ParkersBrook']\n",
    "\n",
    "station_name = stations[0]\n",
    "\n",
    "datafile = f'{station_name}-training.tfrecord.gz'\n",
    "file_location = f'/datadrive/stream_data/training/{datafile}'\n",
    "metadata_file = f'/datadrive/stream_data/training/{station_name}-training_metadata.json'\n",
    "with open(metadata_file) as mfile:\n",
    "    metadata = json.load(mfile)\n",
    "ex = metadata['element_spec']['x_data']\n",
    "ey = metadata['element_spec']['y_data']\n",
    "element_spec = (tf.TensorSpec(shape=tuple(ex['shape']), dtype=ex['dtype'], name=ex['name']),\\\n",
    "                tf.TensorSpec(shape=tuple(ey['shape']), dtype=ey['dtype'], name=ey['name']))\n",
    "full_dataset = tf.data.experimental.load(file_location,\\\n",
    "                                          element_spec,\\\n",
    "                                          compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = int(metadata['count'])\n",
    "prp = 0.7\n",
    "TRAIN_SIZE = int(prp * DATASET_SIZE)\n",
    "#VAL_SIZE = int(0 * DATASET_SIZE)\n",
    "TEST_SIZE = int(1-prp * DATASET_SIZE)\n",
    "SHUFFLE_BUFFER_SIZE = 100 \n",
    "BATCH_SIZE = 8 \n",
    "full_dataset = full_dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "train_dataset = full_dataset.take(TRAIN_SIZE)\n",
    "test_dataset = full_dataset.skip(TRAIN_SIZE)\n",
    "print(tf.data.experimental.cardinality(train_dataset).numpy())\n",
    "print(tf.data.experimental.cardinality(test_dataset).numpy())\n",
    "#val_dataset = test_dataset.skip(TEST_SIZE)\n",
    "#test_dataset = test_dataset.take(TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf, ax = plt.subplots(1,3, figsize=(20,4))\\nfor i in range(3):\\n    for images, labels in test_dataset.take(1):\\n        im = images.numpy()\\n        label = labels.numpy()\\n        ax[i].imshow(im)\\n        ax[i].set_title(label)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "f, ax = plt.subplots(1,3, figsize=(20,4))\n",
    "for i in range(3):\n",
    "    for images, labels in test_dataset.take(1):\n",
    "        im = images.numpy()\n",
    "        label = labels.numpy()\n",
    "        ax[i].imshow(im)\n",
    "        ax[i].set_title(label)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class TestModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.conv1 = Conv2D(filters=8, kernel_size=(32, 32), activation='relu')\n",
    "        self.conv2 = Conv2D(filters=4, kernel_size=(16, 16), activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(8, activation='relu')\n",
    "        self.d2 = Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "\n",
    "model = TestModel()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "#train_accuracy = tfa.metrics.RSquare(name='train_R2')\n",
    "#test_accuracy = tfa.metrics.RSquare(name='test_R2')\n",
    "train_accuracy = tf.keras.metrics.RootMeanSquaredError(name='train_RMSE')\n",
    "test_accuracy = tf.keras.metrics.RootMeanSquaredError(name='test_RMSE')\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different behavior\n",
    "    # during training versus inference (e.g. Dropout)\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, Loss: 0.87, Accuracy: 0.93,                Test Loss: 0.93, Test Accuracy: 0.97\n",
      "\n",
      "Epoch 2, Loss: 0.50, Accuracy: 0.53,                Test Loss: 0.71, Test Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2 \n",
    "BATCH_SIZE = 16 \n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for images, labels in train_dataset.batch(BATCH_SIZE):\n",
    "        train_step(images, labels)\n",
    "        \n",
    "    for test_images, test_labels in test_dataset.batch(BATCH_SIZE):\n",
    "        test_step(test_images, test_labels)\n",
    "    template = 'Epoch {}, Loss: {:.2f}, Accuracy: {:.2f},\\\n",
    "                Test Loss: {:.2f}, Test Accuracy: {:.2f}'\n",
    "    #template = 'Epoch {}, Loss: {}, Test Loss: {}'\n",
    "    print(f'')\n",
    "    print(template.format(epoch + 1,\n",
    "                        train_loss.result(),\\\n",
    "                        test_loss.result(),\\\n",
    "                        train_accuracy.result(),\\\n",
    "                        test_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model and fit\n",
    "\n",
    "#BATCH_SIZE = 8 \n",
    "#train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "#test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = tuple(ex['shape'])\n",
    "output_shape = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 960, 1280, 3)]    0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 960, 1280, 16)     448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 960, 1280, 16)     64        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 960, 1280, 16)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 960, 1280, 16)     64        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 960, 1280, 10)     170       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 960, 1280, 1)      11        \n",
      "=================================================================\n",
      "Total params: 757\n",
      "Trainable params: 693\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = basic_cnn(input_shape=input_shape,\\\n",
    "                  output_shape=output_shape,\\\n",
    "                  final_activation='relu')\n",
    "#model = simple_cnn(input_shape=input_shape, output_shape=output_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "epochs = 10 \n",
    "model.compile(loss=rmse, optimizer=opt, metrics=[coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using dataset as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a56f6800c361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, steps, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[0;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;31m# Arguments that shouldn't be passed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[1;32m    734\u001b[0m                        \"dataset as input.\")\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `y` argument is not supported when using dataset as input."
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 7 \n",
    "r_range = 5 \n",
    "batch_size = 8 \n",
    "brightness_range=(0.8,1)\n",
    "datagen = ImageDataGenerator(rescale=1./255,\\\n",
    "                             rotation_range=r_range,\\\n",
    "                             width_shift_range=shift,\\\n",
    "                             height_shift_range=shift,\\\n",
    "                             brightness_range=brightness_range)\n",
    "datagen.fit(x_train, augment=True, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = next(datagen.flow(x_train,y_train, batch_size))\n",
    "f, ax = plt.subplots(1,batch_size, figsize=(20,10))\n",
    "for i in range(batch_size):\n",
    "    ax[i].imshow(z[0][i])\n",
    "    ax[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a98275aafcfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoeff_determination\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m acc_hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size), \\\n\u001b[0m\u001b[1;32m      6\u001b[0m                                \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "epochs = 10 \n",
    "model.compile(loss=rmse, optimizer=opt, metrics=[coeff_determination])\n",
    "\n",
    "acc_hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size), \\\n",
    "                               steps_per_epoch=len(x_train)/batch_size, \\\n",
    "                               epochs=epochs, \\\n",
    "                               class_weight=class_weights,\\\n",
    "                               validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hist:\n",
    "    hist_add = acc_hist.history\n",
    "    for k in hist.keys():\n",
    "        hist[k].extend(hist_add[k])\n",
    "else:\n",
    "    hist = acc_hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hist = acc_hist.history\n",
    "f, ax = plt.subplots(2,1,figsize=(10,8))\n",
    "for k in hist.keys():\n",
    "    if 'loss' in k:\n",
    "        ax[0].plot(hist[k], label=k)\n",
    "    else:\n",
    "        ax[1].plot(hist[k], label=k)\n",
    "ylabels = ['Loss', 'Accuracy']\n",
    "for i in range(2):\n",
    "    ax[i].legend()\n",
    "    ax[i].grid(alpha=0.5)\n",
    "    ax[i].set_ylabel(ylabels[i])\n",
    "    ax[i].set_xlabel('Epoch')\n",
    "f.savefig('/content/output/accuracy.png', dpi=100, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "ii = 7 \n",
    "jj = 7\n",
    "sample_i = np.random.choice(len(x_test), ii*jj, replace=False).reshape((ii,jj))\n",
    "label = ['low flow','mid flow','high flow']\n",
    "color = ['orange', 'darkblue']\n",
    "f,ax = plt.subplots(ii, jj, figsize=(18,30))\n",
    "for i in range(ii):\n",
    "    for j in range(jj):\n",
    "        s = sample_i[i][j]\n",
    "        ax[i][j].imshow(x_test[s])\n",
    "        ax[i][j].set_axis_off()\n",
    "        ax[i][j].set_title('%s\\nFlowrate: %s\\nTrue:%s\\nPredicted:%s'%(dates_test[s],y_test_flow[s],\\\n",
    "                                             label[np.argmax(y_test[s])],label[np.argmax(y_hat[s])]),\\\n",
    "                                                         color=color[np.argmax(y_test[s])==np.argmax(y_hat[s])])\n",
    "f.savefig('/content/output/validation.png', dpi=100, bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(y_hat,axis=1))\n",
    "plot_confusion_matrix(cm, classes=label, outname='/content/output/conf_mat.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"/content/output/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/content/output/model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "plot_model(model, to_file='/content/output/model_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
